{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V27lDCUsL0je",
        "outputId": "5f53f041-eaa9-48c2-8a68-3e508eb41791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hV97_t-pOa1N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base URL of the website\n",
        "base_url = \"https://www.vezeeta.com/en/doctor/dermatology/egypt?page=\"\n",
        "\n",
        "# Headers for the request\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "data = []\n",
        "page = 1\n",
        "\n",
        "while True:\n",
        "    # Construct the URL for the current page\n",
        "    url = base_url + str(page)\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Break the loop if the request fails\n",
        "    if response.status_code != 200:\n",
        "        print(f\"No more pages to scrape. Stopped at page {page}.\")\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find all doctor cards on the current page\n",
        "    doctors = soup.find_all(\"div\", class_=\"DoctorCardSubComponentsstyle__DoctorImgContainer-sc-1vq3h7c-9\")\n",
        "    if not doctors:\n",
        "        print(\"No more doctors found. Exiting loop.\")\n",
        "        break\n",
        "\n",
        "    for index, doctor in enumerate(doctors):\n",
        "        # Extract image URL\n",
        "        #image_section = doctor.find(\"img\")\n",
        "        #image_url = image_section[\"src\"] if image_section else None\n",
        "\n",
        "        # Extract doctor details\n",
        "        name_section = doctor.find_next(\"h4\")\n",
        "        name = name_section.text.strip() if name_section else None\n",
        "\n",
        "        description_section = doctor.find_next(\"p\")\n",
        "        description = description_section.text.strip() if description_section else None\n",
        "\n",
        "        rating_section = doctor.find_next(\"span\", class_=\"StarRatingstyle__StarRatingContainer-sc-16vjtpf-0\")\n",
        "        rating = rating_section.text.strip() if rating_section else None\n",
        "\n",
        "        # Extract other information\n",
        "        fees_section = doctor.find_next(\"span\", {\"data-testid\": f\"doctor-card-{index}_fees-row_value\"})\n",
        "        fees = fees_section.text.strip() if fees_section else None\n",
        "\n",
        "        waiting_time_section = doctor.find_next(\"span\", {\"data-testid\": f\"doctor-card-{index}_waiting-time\"})\n",
        "        waiting_time = waiting_time_section.text.strip() if waiting_time_section else None\n",
        "\n",
        "        clinic_section = doctor.find_next(\"span\", {\"data-testid\": f\"doctor-card-{index}_address\"})\n",
        "        clinic_name = clinic_section.text.strip() if clinic_section else None\n",
        "\n",
        "        contact_section = doctor.find_next(\"a\", {\"data-testid\": f\"doctor-card-{index}_hotline-row\"})\n",
        "        contact_number = contact_section.text.strip() if contact_section else None\n",
        "\n",
        "        # Append data\n",
        "        data.append({\n",
        "            \"Doctor Name\": name,\n",
        "            \"Description\": description,\n",
        "            \"Rating\": rating,\n",
        "            \"Fees\": fees,\n",
        "            \"Waiting Time\": waiting_time,\n",
        "            \"Clinic Name\": clinic_name,\n",
        "            \"Contact Number\": contact_number,\n",
        "            \"Image URL\": image_url,\n",
        "        })\n",
        "\n",
        "    print(f\"Page {page} scraped successfully.\")\n",
        "    page += 1\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the data to an Excel file\n",
        "excel_filename = \"doctors_data.xlsx\"\n",
        "df.to_excel(excel_filename, index=False)\n",
        "\n",
        "print(f\"Data has been successfully scraped and saved to {excel_filename}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOzGeD7GOYoo",
        "outputId": "0dcb53d9-5bd2-4107-9b4d-d3b96ea95069"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1 scraped successfully.\n",
            "Page 2 scraped successfully.\n",
            "Page 3 scraped successfully.\n",
            "Page 4 scraped successfully.\n",
            "Page 5 scraped successfully.\n",
            "Page 6 scraped successfully.\n",
            "Page 7 scraped successfully.\n",
            "Page 8 scraped successfully.\n",
            "Page 9 scraped successfully.\n",
            "Page 10 scraped successfully.\n",
            "Page 11 scraped successfully.\n",
            "Page 12 scraped successfully.\n",
            "Page 13 scraped successfully.\n",
            "Page 14 scraped successfully.\n",
            "Page 15 scraped successfully.\n",
            "Page 16 scraped successfully.\n",
            "Page 17 scraped successfully.\n",
            "Page 18 scraped successfully.\n",
            "Page 19 scraped successfully.\n",
            "Page 20 scraped successfully.\n",
            "Page 21 scraped successfully.\n",
            "Page 22 scraped successfully.\n",
            "Page 23 scraped successfully.\n",
            "Page 24 scraped successfully.\n",
            "Page 25 scraped successfully.\n",
            "Page 26 scraped successfully.\n",
            "Page 27 scraped successfully.\n",
            "Page 28 scraped successfully.\n",
            "Page 29 scraped successfully.\n",
            "Page 30 scraped successfully.\n",
            "Page 31 scraped successfully.\n",
            "Page 32 scraped successfully.\n",
            "Page 33 scraped successfully.\n",
            "Page 34 scraped successfully.\n",
            "Page 35 scraped successfully.\n",
            "Page 36 scraped successfully.\n",
            "Page 37 scraped successfully.\n",
            "Page 38 scraped successfully.\n",
            "Page 39 scraped successfully.\n",
            "Page 40 scraped successfully.\n",
            "Page 41 scraped successfully.\n",
            "Page 42 scraped successfully.\n",
            "Page 43 scraped successfully.\n",
            "Page 44 scraped successfully.\n",
            "Page 45 scraped successfully.\n",
            "Page 46 scraped successfully.\n",
            "Page 47 scraped successfully.\n",
            "Page 48 scraped successfully.\n",
            "Page 49 scraped successfully.\n",
            "Page 50 scraped successfully.\n",
            "Page 51 scraped successfully.\n",
            "Page 52 scraped successfully.\n",
            "Page 53 scraped successfully.\n",
            "Page 54 scraped successfully.\n",
            "Page 55 scraped successfully.\n",
            "Page 56 scraped successfully.\n",
            "Page 57 scraped successfully.\n",
            "Page 58 scraped successfully.\n",
            "Page 59 scraped successfully.\n",
            "Page 60 scraped successfully.\n",
            "Page 61 scraped successfully.\n",
            "Page 62 scraped successfully.\n",
            "Page 63 scraped successfully.\n",
            "Page 64 scraped successfully.\n",
            "Page 65 scraped successfully.\n",
            "Page 66 scraped successfully.\n",
            "Page 67 scraped successfully.\n",
            "Page 68 scraped successfully.\n",
            "Page 69 scraped successfully.\n",
            "Page 70 scraped successfully.\n",
            "Page 71 scraped successfully.\n",
            "Page 72 scraped successfully.\n",
            "Page 73 scraped successfully.\n",
            "Page 74 scraped successfully.\n",
            "Page 75 scraped successfully.\n",
            "Page 76 scraped successfully.\n",
            "Page 77 scraped successfully.\n",
            "Page 78 scraped successfully.\n",
            "Page 79 scraped successfully.\n",
            "No more doctors found. Exiting loop.\n",
            "Data has been successfully scraped and saved to doctors_data.xlsx.\n"
          ]
        }
      ]
    }
  ]
}